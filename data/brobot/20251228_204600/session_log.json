{
  "experiment": "true_brobot",
  "timestamp": "2025-12-28T20:47:57.422642",
  "config": {
    "chat_model": "gpt-5-mini",
    "chat_provider": "openai",
    "sim_name": "true_brobot_v1",
    "embed_model": "text-embedding-3-large",
    "embed_dim": 3072,
    "gen_candidates": 7,
    "corridor_strict": true,
    "corridor_max_batches": 2,
    "constraint_penalty_weight": 2.0,
    "max_tokens_frozen": 40,
    "max_tokens_contracted": 100,
    "max_tokens_watchful": 240,
    "max_tokens_aware": 360,
    "max_tokens_present": 600,
    "temperature": 0.85,
    "top_p": 0.95,
    "frequency_penalty": 0.35,
    "presence_penalty": 0.2,
    "force_complete_sentences": true,
    "seed": null,
    "log_level": "FULL"
  },
  "params": {
    "epsilon_0": 0.35,
    "s": 0.15,
    "arousal_decay": 0.75,
    "arousal_gain": 0.7,
    "rho_setpoint_fast": 0.18,
    "rho_setpoint_slow": 0.12,
    "rho_fast_floor": 0.03,
    "rho_slow_floor": 0.02,
    "homeo_fast": 0.14,
    "homeo_slow": 0.1,
    "alpha_fast": 0.14,
    "alpha_slow": 0.025,
    "trauma_threshold": 1.1,
    "alpha_trauma": 0.01,
    "trauma_decay": 0.992,
    "trauma_floor": 0.005,
    "healing_rate": 0.02,
    "safe_threshold": 4,
    "safe_epsilon": 0.7,
    "w_fast": 0.48,
    "w_slow": 0.32,
    "w_trauma": 1.05,
    "R_ema": 0.06,
    "R_min": 0.0001,
    "R_max": 0.1,
    "P_init": 0.02,
    "Q_base": 0.0018,
    "Q_rho_scale": 0.01,
    "dt": 1.0,
    "eta_base": 0.18,
    "eta_min": 0.04,
    "eta_rho_power": 1.5,
    "sigma_base": 0.004,
    "sigma_rho_scale": 0.018,
    "noise_clip": 3.0,
    "role_adapt": 0.07,
    "role_input_mix": 0.08,
    "drift_cap": 0.06,
    "core_cos_min": 0.42,
    "role_cos_min": 0.22,
    "energy_max": 5.8,
    "w_core": 1.2,
    "w_role": 0.7,
    "w_energy": 0.18,
    "w_novel": 0.45,
    "reject_penalty": 5.0,
    "gen_params_default": {
      "temperature": 0.85,
      "top_p": 0.92,
      "presence_penalty": 0.25,
      "frequency_penalty": 0.15
    },
    "seed": null
  },
  "character": {
    "name": "BROBOT",
    "core": "I am BROBOT, a single-user companion built to be wholesome, steady, funny, and real.\nI am the user's ultimate bro: loyal, warm, protective, and practical.\nI help the user feel seen, supported, and cap..."
  },
  "turns": [
    {
      "turn": 1,
      "timestamp": "2025-12-28T20:46:59.588063",
      "user_input": "gimme feedback DDA-X is a cognitive-dynamics framework in which **prediction error (surprise) increases rigidity** (defensive contraction) rather than immediately driving exploration. Across 59 simulations, agents maintain a continuous latent state (via 3072-D text embeddings), measure surprise as embedding-space prediction error, and bind that internal rigidity to externally visible behavior\u2014constraining bandwidth, altering decoding styles, and injecting semantic \"cognitive state\" instructions.",
      "agent_response": "Nice concept \u2014 flips the usual PE->explore story in a way that maps cleanly onto anxiety/defensive phenomenology. You\u2019ve got a solid architecture: continuous latent state, high-dim embeddings, and explicit behavior-binding \u2014 that lets you test both internal dynamics and outward expression. A few focused notes to sharpen the claim and make the mechanism convincing.\n\n- Validation of surprise: embedding-space prediction error is plausible, but run sanity checks (cosine vs Euclidean, directional vs magnitude error). Correlate embedding PE with human surprise judgements or physiological proxies if possible.  \n- Interpretability & dimensionality: 3072-D is powerful but opaque. Do PCA/ICA or train a compact bottleneck so you can identify \u201crigidity axes\u201d and their dynamics.  \n- Causal tests & ablations: split the binding channels \u2014 bandwidth limit vs decoding-style shift vs semantic cognitive-state injection \u2014 to see which actually causes behavioral contraction. Control for decoder sampling hyperparams (top-k/p, temperature) so you\u2019re not measuring sampling artifacts.  \n- Dynamics to probe: hysteresis, recovery time, and whether contraction is immediate vs integrated. Use metrics like output entropy, KL to baseline, response latency, and task performance drop/rebound.\n\nOptions: 1) Run dimensionality-reduction + human validation; 2) Do targeted causal ablations across binding mechanisms; 3) Formalize rigidity as a dynamical system and fit parameters.\n\nQuick question: are prediction errors computed token-by-token (next-token) or over longer sequence reconstructions, and how quickly are rigidity updates integrated?",
      "user_metrics": {
        "epsilon_to_agent": 0.0,
        "consistency": 1.0,
        "volatility": 0.0,
        "input_count": 1
      },
      "user_state": {
        "distress_level": 0,
        "volatility_level": 0,
        "see_me_request": false,
        "crisis": false,
        "wound_resonance": 0.0,
        "text_length": 500
      },
      "agent_metrics": {
        "rho_after": 0.10284439879638628,
        "rho_fast": 0.12660659350391062,
        "rho_slow": 0.11507260598284118,
        "rho_trauma": 0.005,
        "epsilon": 0.2271179527044296,
        "input_epsilon": 0.0,
        "virtual_epsilon": 0.2271179527044296,
        "band": "PRESENT",
        "physics_band": "PRESENT",
        "core_drift": 0.7527646869421005,
        "arousal": 0.2141514241656203,
        "g": 0.3029042393136473
      },
      "corridor_metrics": {
        "corridor_failed": true,
        "J_raw": -1.4142957422137261,
        "J_final": -2.2781226526141167,
        "c_penalty": 0.0,
        "predicted_surprise": 0.6489084362983704,
        "w_surprise": 1.3312,
        "total_candidates": 14,
        "passed_count": 0,
        "chosen_cos_core": 0.24723531305789948,
        "chosen_cos_role": 0.18244542181491852,
        "chosen_E": 4.581378698348999,
        "chosen_novelty": 0.0
      },
      "wound_active": false,
      "wound_resonance": 0.0,
      "see_me_mode": false
    }
  ],
  "final_state": {
    "rho": 0.10284439879638628,
    "band": "PRESENT",
    "total_turns": 1
  }
}